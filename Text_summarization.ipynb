{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-f1meMme1Fe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import textwrap\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "GYY2veCde-9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('bbc_text_cls.csv')"
      ],
      "metadata": {
        "id": "hU9ayAnqfCbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "xtbKe7v5fHDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = df[df.labels == 'business']['text'].sample(random_state=42)"
      ],
      "metadata": {
        "id": "iRoCm4aSfJmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap(x):\n",
        "  return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
      ],
      "metadata": {
        "id": "__818lr8fOas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrap(doc.iloc[0]))"
      ],
      "metadata": {
        "id": "DFQv4V6LfR-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents = nltk.sent_tokenize(doc.iloc[0].split(\"\\n\", 1)[1])"
      ],
      "metadata": {
        "id": "sIcltRkpfVLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featurizer = TfidfVectorizer(\n",
        "    stop_words=stopwords.words('english'),\n",
        "    norm='l1',\n",
        ")"
      ],
      "metadata": {
        "id": "t1KXxHL_fZzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = featurizer.fit_transform(sents)"
      ],
      "metadata": {
        "id": "aTD-Q5lifcVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_score(tfidf_row):\n",
        "  # return the average of the non-zero values\n",
        "  # of the tf-idf vector representation of a sentence\n",
        "  x = tfidf_row[tfidf_row != 0]\n",
        "  return x.mean()"
      ],
      "metadata": {
        "id": "9jZnqoTwfe6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = np.zeros(len(sents))\n",
        "for i in range(len(sents)):\n",
        "  score = get_sentence_score(X[i,:])\n",
        "  scores[i] = score"
      ],
      "metadata": {
        "id": "s-mrEIC9fh34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_idx = np.argsort(-scores)"
      ],
      "metadata": {
        "id": "fXudCMIMfpnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Many options for how to choose which sentences to include:\n",
        "\n",
        "# 1) top N sentences\n",
        "# 2) top N words or characters.\n",
        "# 3) top X% sentences or top X% words\n",
        "# 4) sentences with scores > average score\n",
        "# 5) sentences with scores > factor * average score\n",
        "\n",
        "# You also don't have to sort. May make more sense in order.\n",
        "\n",
        "print(\"Generated summary:\")\n",
        "for i in sort_idx[:5]:\n",
        "  print(wrap(\"%.2f: %s\" % (scores[i], sents[i])))"
      ],
      "metadata": {
        "id": "KhOtslF6fr45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}