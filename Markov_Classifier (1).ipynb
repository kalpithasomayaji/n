{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "s7lo8Mn-fYG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_files = [\n",
        "  'edgar_allan_poe.txt',\n",
        "  'robert_frost.txt',\n",
        "]"
      ],
      "metadata": {
        "id": "bepw9L52fdUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head edgar_allan_poe.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZodJpq6fo_M",
        "outputId": "546fd212-1d23-4718-cd19-25eba66c1e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LO! Death hath rear'd himself a throne\n",
            "In a strange city, all alone,\n",
            "Far down within the dim west\n",
            "Where the good, and the bad, and the worst, and the best,\n",
            "Have gone to their eternal rest.\n",
            "â€‰\n",
            "There shrines, and palaces, and towers\n",
            "Are not like any thing of ours\n",
            "Oh no! O no! ours never loom\n",
            "To heaven with that ungodly gloom!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head robert_frost.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUElnykFftW8",
        "outputId": "2a48bafd-8b8a-4fc2-e445-903b5b9abe3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two roads diverged in a yellow wood,\n",
            "And sorry I could not travel both\n",
            "And be one traveler, long I stood\n",
            "And looked down one as far as I could\n",
            "To where it bent in the undergrowth; \n",
            "\n",
            "Then took the other, as just as fair,\n",
            "And having perhaps the better claim\n",
            "Because it was grassy and wanted wear,\n",
            "Though as for that the passing there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collect data into lists\n",
        "input_texts = []\n",
        "labels = []\n",
        "\n",
        "for label, f in enumerate(input_files):\n",
        "  print(f\"{f} corresponds to label {label}\")\n",
        "\n",
        "  for line in open(f):\n",
        "    line = line.rstrip().lower()\n",
        "    if line:\n",
        "      # remove punctuation\n",
        "      line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "      input_texts.append(line)\n",
        "      labels.append(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy-NOVcafy_3",
        "outputId": "ced432c2-37ab-4945-fcb0-8ff414622931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edgar_allan_poe.txt corresponds to label 0\n",
            "robert_frost.txt corresponds to label 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, test_text, Ytrain, Ytest = train_test_split(input_texts, labels)"
      ],
      "metadata": {
        "id": "erJCkADrf9Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Ytrain), len(Ytest)"
      ],
      "metadata": {
        "id": "v8RdfGiqgZzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[:5]"
      ],
      "metadata": {
        "id": "Vk1IMuSzgeLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ytrain[:5]"
      ],
      "metadata": {
        "id": "5yeCcfRjghSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 1\n",
        "word2idx = {'<unk>': 0}"
      ],
      "metadata": {
        "id": "fZeJqH25grjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# populate word2idx\n",
        "for text in train_text:\n",
        "    tokens = text.split()\n",
        "    for token in tokens:\n",
        "      if token not in word2idx:\n",
        "        word2idx[token] = idx\n",
        "        idx += 1"
      ],
      "metadata": {
        "id": "LDSIQG_dgukL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx"
      ],
      "metadata": {
        "id": "hT_XOEYCg0sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2idx)"
      ],
      "metadata": {
        "id": "w--Xpt-0g4Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data into integer format\n",
        "train_text_int = []\n",
        "test_text_int = []\n",
        "\n",
        "for text in train_text:\n",
        "  tokens = text.split()\n",
        "  line_as_int = [word2idx[token] for token in tokens]\n",
        "  train_text_int.append(line_as_int)\n",
        "\n",
        "for text in test_text:\n",
        "  tokens = text.split()\n",
        "  line_as_int = [word2idx.get(token, 0) for token in tokens]\n",
        "  test_text_int.append(line_as_int)"
      ],
      "metadata": {
        "id": "rTivh7Pzg-jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_int[100:105]"
      ],
      "metadata": {
        "id": "p7KmVLjGhFlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize A and pi matrices - for both classes\n",
        "V = len(word2idx)\n",
        "\n",
        "A0 = np.ones((V, V))\n",
        "pi0 = np.ones(V)\n",
        "\n",
        "A1 = np.ones((V, V))\n",
        "pi1 = np.ones(V)"
      ],
      "metadata": {
        "id": "nsTl_el7hWnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute counts for A and pi\n",
        "def compute_counts(text_as_int, A, pi):\n",
        "  for tokens in text_as_int:\n",
        "    last_idx = None\n",
        "    for idx in tokens:\n",
        "      if last_idx is None:\n",
        "        # it's the first word in a sentence\n",
        "        pi[idx] += 1\n",
        "      else:\n",
        "        # the last word exists, so count a transition\n",
        "        A[last_idx, idx] += 1\n",
        "\n",
        "      # update last idx\n",
        "      last_idx = idx\n",
        "\n",
        "\n",
        "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 0], A0, pi0)\n",
        "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 1], A1, pi1)"
      ],
      "metadata": {
        "id": "_g-j9LZ6hhH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize A and pi so they are valid probability matrices\n",
        "# convince yourself that this is equivalent to the formulas shown before\n",
        "A0 /= A0.sum(axis=1, keepdims=True)\n",
        "pi0 /= pi0.sum()\n",
        "\n",
        "A1 /= A1.sum(axis=1, keepdims=True)\n",
        "pi1 /= pi1.sum()"
      ],
      "metadata": {
        "id": "wvfd8_n0hiMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log A and pi since we don't need the actual probs\n",
        "logA0 = np.log(A0)\n",
        "logpi0 = np.log(pi0)\n",
        "\n",
        "logA1 = np.log(A1)\n",
        "logpi1 = np.log(pi1)"
      ],
      "metadata": {
        "id": "pMh8jUTVhpIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute priors\n",
        "count0 = sum(y == 0 for y in Ytrain)\n",
        "count1 = sum(y == 1 for y in Ytrain)\n",
        "total = len(Ytrain)\n",
        "p0 = count0 / total\n",
        "p1 = count1 / total\n",
        "logp0 = np.log(p0)\n",
        "logp1 = np.log(p1)\n",
        "p0, p1"
      ],
      "metadata": {
        "id": "3lhFB1eHhvoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a classifier\n",
        "class Classifier:\n",
        "  def __init__(self, logAs, logpis, logpriors):\n",
        "    self.logAs = logAs\n",
        "    self.logpis = logpis\n",
        "    self.logpriors = logpriors\n",
        "    self.K = len(logpriors) # number of classes\n",
        "\n",
        "  def _compute_log_likelihood(self, input_, class_):\n",
        "    logA = self.logAs[class_]\n",
        "    logpi = self.logpis[class_]\n",
        "\n",
        "    last_idx = None\n",
        "    logprob = 0\n",
        "    for idx in input_:\n",
        "      if last_idx is None:\n",
        "        # it's the first token\n",
        "        logprob += logpi[idx]\n",
        "      else:\n",
        "        logprob += logA[last_idx, idx]\n",
        "\n",
        "      # update last_idx\n",
        "      last_idx = idx\n",
        "\n",
        "    return logprob\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    predictions = np.zeros(len(inputs))\n",
        "    for i, input_ in enumerate(inputs):\n",
        "      posteriors = [self._compute_log_likelihood(input_, c) + self.logpriors[c] \\\n",
        "             for c in range(self.K)]\n",
        "      pred = np.argmax(posteriors)\n",
        "      predictions[i] = pred\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "JS9FNGZch2Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# each array must be in order since classes are assumed to index these lists\n",
        "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])"
      ],
      "metadata": {
        "id": "Ul8Xy1ugh-Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ptrain = clf.predict(train_text_int)\n",
        "print(f\"Train acc: {np.mean(Ptrain == Ytrain)}\")"
      ],
      "metadata": {
        "id": "A_mZTgr1iDQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ptest = clf.predict(test_text_int)\n",
        "print(f\"Test acc: {np.mean(Ptest == Ytest)}\")"
      ],
      "metadata": {
        "id": "Yo0b0BRGiIH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "# read about F-score: https://en.wikipedia.org/wiki/F-score"
      ],
      "metadata": {
        "id": "kaBeH_ziiMCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(Ytrain, Ptrain)\n",
        "cm"
      ],
      "metadata": {
        "id": "CJhMGjmSiSa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_test = confusion_matrix(Ytest, Ptest)\n",
        "cm_test"
      ],
      "metadata": {
        "id": "vtLqac4-iY7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(Ytrain, Ptrain)"
      ],
      "metadata": {
        "id": "OERohDNBieHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(Ytest, Ptest)"
      ],
      "metadata": {
        "id": "1vbLcyZjiiBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}